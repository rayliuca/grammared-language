# Docker Compose configuration for Grammared Language
# This is a placeholder/template for orchestrating the services

services:
  # Triton Inference Server
  triton-server:
    build:
      context: .
      dockerfile: docker/triton/Dockerfile
    image: grammared-triton:latest
    container_name: grammared-triton
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - MODEL_REPOSITORY=/models
      - LOG_VERBOSE=0
      - TRANSFORMERS_CACHE=/cache
      - HF_HOME=/cache
    ports:
      - "8000:8000"  # HTTP
      - "8001:8001"  # gRPC
      - "8002:8002"  # Metrics
    volumes:
      - ./config/triton:/config:ro
      - triton-cache:/cache  # HuggingFace model cache
      - ./hf_token:/cache/token  # HuggingFace token for private models
      - ./model_config.yaml:/model_config.yaml:ro  # Model configuration
      # - ./triton_server/example_model_repository:/models:ro  # Example models
    # shm_size: '1gb'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v2/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - grammared-network
    restart: unless-stopped

  # API Service
  api-service:
    build:
      context: .
      dockerfile: docker/api/Dockerfile
    image: grammared-api:latest
    container_name: grammared-api
    ports:
      - "50051:50051"
    volumes:
      - ./logs:/app/logs
      - ./model_config.yaml:/model_config.yaml:ro  # Model configuration
      - ./data:/data
      # - triton-cache:/cache  # HuggingFace model cache
      - ./hf_token:/cache/token  # HuggingFace token for private models
    environment:
      # - GRRAMMARED_LANGUAGE__API_PORT=50051
      - LOG_LEVEL=INFO
      - GRAMMARED_LANGUAGE__MODEL_CONFIG_PATH=/model_config.yaml
      # - TRANSFORMERS_CACHE=/cache
      # - HF_HOME=/cache
    depends_on:
      triton-server:
        condition: service_healthy
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 3
    #   start_period: 10s
    networks:
      - grammared-network
    restart: unless-stopped

networks:
  grammared-network:
    # driver: bridge

# Volumes for persistent data
volumes:
  triton-cache:
    driver: local
