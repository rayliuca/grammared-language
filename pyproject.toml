[project.urls]
"Homepage" = "https://github.com/rayliuca/grammared-language"

[project]
name = "grammared-language"
version = "0.1.4"
description = "Grammar error correction backend with Triton and GRPC integration"
readme = "README.md"
requires-python = ">=3.11"
license = { file = "LICENSE.md" }
authors = [ { name = "Ray Liu", email = "ray@rayliu.ca" } ]
keywords = ["nlp", "machine-learning", 'natural-language-processing', 'spellcheck', 'grammar', 'triton', 'languagetool', 'triton-inference-server', 'llm']

# Core runtime dependencies (keep minimal; extras provide larger optional deps)
dependencies = [
  "pip>=25.3",
  "pydantic",
  "openai",
  "jinja2>=3.1.6",
  "transformers>=4.30.0",
  "scikit-learn",
  "tritonclient[grpc]>=2.60.0",
  "gector-triton",
  "fastapi>=0.128.0",
  "errant>=3.0.0",
  "uvicorn",
  "grpcio",
  "grpcio-tools",
  "protobuf>=5.29.5",
  "torch",
  "numpy",
  "sentencepiece>=0.2.1",
]

[project.optional-dependencies]

# fix dependencies in docker
docker = [
  "pydantic==2.12.5",
  "openai==2.15.0",
  "jinja2==3.1.6",
  "transformers==4.57.6",
  "scikit-learn==1.8.0",
  "tritonclient[grpc]==2.64.0",
  "gector-triton",
  "fastapi==0.128.0",
  "errant==3.0.0",
  "spacy==3.8.11",
  "uvicorn==0.40.0",
  "grpcio==1.67.1",
  "grpcio-tools==1.67.1",
  "numpy==1.26.4"
]

triton = [
  "torch",
  "transformers[torch]==4.57.6",
  "optimum[onnxruntime-gpu]",
  "bitsandbytes",
  "accelerate",
]

# cpu only, onnxruntime-gpu not supported on arm
triton-arm = [
  "transformers[torch]==4.57.6",
  "optimum[onnxruntime]",
  "bitsandbytes",
  "accelerate",
  "torch==2.10.0+cpu"
]

dev = [
  "pytest>=7.0.0",
  "pytest-asyncio>=0.21.0",
  "pytest-cov>=4.0.0",
  "pytest-mock>=3.10.0",
  "black>=23.0.0",
  "isort>=5.12.0",
  "mypy>=1.0.0",
  "ruff>=0.1.0",
  "pre-commit>=3.0.0",
  "datasets"
]

test = [
  "pytest>=7.0.0",
  "pytest-asyncio>=0.21.0",
  "pytest-mock>=3.10.0",
  "requests>=2.28.0",
]

all = [
  "grammared-language[triton,dev,test]"
]

[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
where = ["."]
include = ["grammared_language*"]

[tool.setuptools.package-data]
grammared_language = [
  "triton/builder/triton_templates/*.jinja",
]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = ["-ra", "--strict-markers", "--strict-config", "-v"]
markers = [
    "unit: Unit tests that don't require external services",
    "integration: Integration tests that require services (gRPC, API)",
    "functional: Functional tests for Triton models",
    "slow: Tests that take a long time to run",
    "requires_triton: Tests that require Triton server",
    "requires_grpc: Tests that require gRPC server",
]

[tool.black]
line-length = 88
target-version = ["py310"]

[tool.isort]
profile = "black"

[tool.uv.sources]
torch = { marker = "extra == 'triton-arm'", index = "pytorch-cpu" }

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true
