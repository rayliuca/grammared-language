# Docker Compose configuration for Grammared Language
# This is a placeholder/template for orchestrating the services

services:
  # Triton Inference Server
  triton-server:
    build:
      context: .
      dockerfile: docker/triton/Dockerfile
    image: grammared-language-triton:latest
    container_name: grammared-triton
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - MODEL_REPOSITORY=/models
      - LOG_VERBOSE=0
      - TRANSFORMERS_CACHE=/cache
      - HF_HOME=/cache
    ports:
      - "8000:8000"  # HTTP
      - "8001:8001"  # gRPC
      - "8002:8002"  # Metrics
    volumes:
      - ./config/triton:/config:ro
      - hf-cache:/cache  # HuggingFace model cache
      # - ./model_config.yaml:/model_config.yaml:ro  # Model configuration
    # shm_size: '1gb'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v2/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - grammared-network
    restart: unless-stopped

  # API Service
  api-service:
    build:
      context: .
      dockerfile: docker/api/Dockerfile
    image: grammared-language-api:latest
    container_name: grammared-api
    ports:
      - "50051:50051"
      - "50052:50052"
    volumes:
      - ./logs:/app/logs
      - ./data:/data
      - hf-cache:/cache  # HuggingFace model cache
    environment:
      # - GRRAMMARED_LANGUAGE__API_PORT=50051
      - LOG_LEVEL=INFO
      - GRAMMARED_LANGUAGE__MODEL_CONFIG_PATH=/model_config.yaml
      - TRANSFORMERS_CACHE=/cache
      - HF_HOME=/cache
    depends_on:
      triton-server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:50052/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - grammared-network
    restart: unless-stopped
  languagetool:
    image: meyay/languagetool:latest
    container_name: languagetool
    restart: unless-stopped
    read_only: true
    tmpfs:
      - /tmp:exec
    cap_drop:
      - ALL
    cap_add:
      - CAP_CHOWN
      - CAP_DAC_OVERRIDE
      - CAP_SETUID
      - CAP_SETGID
    security_opt:
      - no-new-privileges
    ports:
      - 8081:8081
    environment:
      download_ngrams_for_langs: en
      MAP_UID: 1000
      MAP_GID: 1000
      langtool_remoteRulesFile: /remote-rule-config.json      
    volumes:
      - ./ngrams:/ngrams:ro
      - fasttext:/fasttext
      - ./example_language_tool_configs/remote-rule-config.json:/remote-rule-config.json:ro
    networks:
      - grammared-network
      - cloudflared

  cloudflared:
    image: cloudflare/cloudflared
    container_name: cloudflared
    environment:
      - TZ=Europe/Amsterdam # Change this to your timezone
      - TUNNEL_TOKEN=${CLOUDFLARED_TUNNEL_TOKEN}
    restart: unless-stopped
    command: tunnel --no-autoupdate run
    networks:
      - cloudflared

networks:
  grammared-network:
  cloudflared:
    name: cloudflared
# Volumes for persistent data
volumes:
  hf-cache:
    driver: local
  fasttext:
    driver: local