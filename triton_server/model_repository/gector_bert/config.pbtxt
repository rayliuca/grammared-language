name: "gector_bert"
backend: "python"
max_batch_size: 8

# Hugging face model path. Parameters must follow this
# key/value structure
parameters: {
  key: "huggingface_model",
  value: {string_value: "bert-base-cased"}
}


input [
  {
    name: "input_ids"
    data_type: TYPE_INT64
    dims: [-1]
  },
  {
    name: "attention_mask"
    data_type: TYPE_INT64
    dims: [-1]
  }
]

output [
  {
    name: "logits_labels"
    data_type: TYPE_FP32
    dims: [-1, -1]
  },
  {
    name: "logits_d"
    data_type: TYPE_FP32
    dims: [-1, -1]
  }
]

# Instance groups - configure based on available resources
instance_group [
  {
    count: 1
    # kind: KIND_GPU
    # gpus: [0]
    kind: KIND_CPU
  }
]


# Python backend requires these parameters
parameters: {
  key: "EXECUTION_ENV_PATH",
  value: {string_value: "/opt/tritonserver/python_backend_env"}
}

# Dynamic batching for better throughput
dynamic_batching {
  preferred_batch_size: [1, 2, 4, 8]
  max_queue_delay_microseconds: 100
}

# Model versioning
version_policy: {
  specific {
    versions: [1]
  }
}
